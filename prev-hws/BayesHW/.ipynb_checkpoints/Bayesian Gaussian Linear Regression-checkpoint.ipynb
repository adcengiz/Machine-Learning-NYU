{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.matlib as matlib\n",
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "# import support_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData(dataSize, noiseParams, actual_weights):\n",
    "    # x1: from [0,1) to [-1,1)\n",
    "    x1 = -1 + 2 * np.random.rand(dataSize, 1)\n",
    "    # appending the bias term\n",
    "    xtrain = np.matrix(np.c_[np.ones((dataSize, 1)), x1])\n",
    "    # random noise\n",
    "    noise = np.matrix(np.random.normal(\n",
    "                            noiseParams[\"mean\"],\n",
    "                            noiseParams[\"var\"],\n",
    "                            (dataSize, 1)))\n",
    "\n",
    "    ytrain = (xtrain * actual_weights) + noise\n",
    "\n",
    "    return xtrain, ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_plots(actual_weights, xtrain, ytrain, likelihood_var, prior, likelihoodFunc, getPosteriorParams, getPredictiveParams):\n",
    "\n",
    "    # #setup for plotting\n",
    "    #\n",
    "    showProgressTillDataRows = [1, 2, 10, -1]\n",
    "    numRows = 1 + len(showProgressTillDataRows)\n",
    "    numCols = 4\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplots_adjust(hspace=.8, wspace=.8)\n",
    "\n",
    "    plotWithoutSeeingData(prior, numRows, numCols)\n",
    "\n",
    "    # see data for as many rounds as specified and plot\n",
    "    for roundNum, rowNum in enumerate(showProgressTillDataRows):\n",
    "        current_row = roundNum + 1\n",
    "        first_column_pos = (current_row * numCols) + 1\n",
    "\n",
    "        # #plot likelihood on latest point\n",
    "        plt.subplot(numRows, numCols, first_column_pos)\n",
    "\n",
    "\n",
    "        likelihoodFunc_with_data = lambda W: likelihoodFunc(W,\n",
    "                                                      xtrain[:rowNum,],\n",
    "                                                      ytrain[:rowNum],\n",
    "                                                      likelihood_var)\n",
    "        contourPlot(likelihoodFunc_with_data, actual_weights)\n",
    "\n",
    "        # plot updated posterior on points seen till now\n",
    "        x_seen = xtrain[:rowNum]\n",
    "        y_seen = ytrain[:rowNum]\n",
    "        mu, cov = getPosteriorParams(x_seen, y_seen,\n",
    "                                      prior, likelihood_var)\n",
    "        posteriorDistr = multivariate_normal(mu.T.tolist()[0], cov)\n",
    "        posteriorFunc = lambda x: posteriorDistr.pdf(x)\n",
    "        plt.subplot(numRows, numCols, first_column_pos + 1)\n",
    "        contourPlot(posteriorFunc, actual_weights)\n",
    "\n",
    "        # plot lines\n",
    "        dataSeen = np.c_[x_seen[:, 1], y_seen]\n",
    "        plt.subplot(numRows, numCols, first_column_pos + 2)\n",
    "        plotSampleLines(mu, cov, dataPoints=dataSeen)\n",
    "\n",
    "        # plot predictive\n",
    "        plt.subplot(numRows, numCols, first_column_pos + 3)\n",
    "        postMean, postVar = getPosteriorParams(x_seen, y_seen, prior)\n",
    "        plotPredictiveDistribution(getPredictiveParams, postMean, postVar)\n",
    "\n",
    "    # #show the final plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotWithoutSeeingData(prior, numRows, numCols):\n",
    "\n",
    "    #Blank likelihood\n",
    "    plt.subplot(numRows, numCols, 1, axisbg='grey')\n",
    "    plt.title(\"Likelihood\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlim([-0.9, 0.9])\n",
    "    plt.ylim([-0.9, 0.9])\n",
    "\n",
    "    #Prior\n",
    "    priorDistribution = multivariate_normal(mean=prior[\"mean\"].T.tolist()[0],\n",
    "        cov=prior[\"var\"])\n",
    "    priorFunc = lambda x:priorDistribution.pdf(x)\n",
    "    plt.subplot(numRows, numCols, 2)\n",
    "    plt.title(\"Prior/Posterior\")\n",
    "    contourPlot(priorFunc)\n",
    "\n",
    "    # Plot initially valid lines (no data seen)\n",
    "    plt.subplot(numRows, numCols, 3)\n",
    "    plt.title(\"Data Space\")\n",
    "    plotSampleLines(prior[\"mean\"], prior[\"var\"])\n",
    "\n",
    "    # Blank predictive\n",
    "    plt.subplot(numRows, numCols, 4, axisbg='grey')\n",
    "    plt.title('Predictive Distribution')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.ylim([-1, 1])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contourPlot(distributionFunc, actualWeights=[]):\n",
    "\n",
    "    stepSize = 0.05\n",
    "    array = np.arange(-1, 1, stepSize)\n",
    "    x, y_train = np.meshgrid(array, array)\n",
    "\n",
    "    length = x.shape[0] * x.shape[1]\n",
    "    x_flat = x.reshape((length, 1))\n",
    "    y_flat = y_train.reshape((length, 1))\n",
    "    contourPoints = np.c_[x_flat, y_flat]\n",
    "\n",
    "    values = map(distributionFunc, contourPoints)\n",
    "    values = np.array(values).reshape(x.shape)\n",
    "\n",
    "    plt.contourf(x, y_train, values)\n",
    "    plt.xlabel(\"w1\")\n",
    "    plt.ylabel(\"w2\")\n",
    "    plt.xticks([-0.5, 0, 0.5])\n",
    "    plt.yticks([-0.5, 0, 0.5])\n",
    "    plt.xlim([-0.9, 0.9])\n",
    "    plt.ylim([-0.9, 0.9])\n",
    "\n",
    "    if(len(actualWeights) == 2):\n",
    "        plt.plot(float(actualWeights[0]), float(actualWeights[1]),\n",
    "                 \"*k\", ms=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the specified number of lines of the form y_train = w0 + w1*x in [-1,1]x[-1,1] by\n",
    "# drawing w0, w1 from a bivariate normal distribution with specified values\n",
    "# for mu = mean and sigma = covariance Matrix. Also plot the data points as\n",
    "# circles.\n",
    "def plotSampleLines(mean, variance,\n",
    "                    numberOfLines=6,\n",
    "                    dataPoints=np.empty((0, 0))):\n",
    "    stepSize = 0.05\n",
    "    # generate and plot lines\n",
    "    for round in range(1, numberOfLines):\n",
    "        weights = np.matrix(np.random.multivariate_normal(mean.T.tolist()[0], variance)).T\n",
    "        x1 = np.arange(-1, 1, stepSize)\n",
    "        x = np.matrix(np.c_[np.ones((len(x1), 1)), x1])\n",
    "        y_train = x * weights\n",
    "\n",
    "        plt.plot(x1, y_train)\n",
    "\n",
    "    # markings\n",
    "    plt.xticks([-1, 0, 1])\n",
    "    plt.yticks([-1, 0, 1])\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.ylim([-1, 1])\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    # plot data points if given\n",
    "    if(dataPoints.size):\n",
    "        plt.plot(dataPoints[:, 0], dataPoints[:, 1],\n",
    "                 \"co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotPredictiveDistribution(getPredictiveParams,postMean, postVar):\n",
    "    stepSize = 0.05\n",
    "    x = np.arange(-1, 1, stepSize)\n",
    "    x = np.matrix(np.c_[np.ones((len(x), 1)), x])\n",
    "    predMeans = np.zeros(x.shape[0])\n",
    "    predStds = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        predMeans[i], predStds[i] = getPredictiveParams(x[i,].T,\n",
    "                                                        postMean,\n",
    "                                                        postVar)\n",
    "    predStds = np.sqrt(predStds)\n",
    "    plt.plot(x[:,1], predMeans, 'b')\n",
    "    plt.plot(x[:,1], predMeans + predStds, 'b--')\n",
    "    plt.plot(x[:,1], predMeans - predStds, 'b--')\n",
    "    plt.xticks([-1, 0, 1])\n",
    "    plt.yticks([-0.5, 0, 0.5])\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.ylim([-1, 1])\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Implement likelihoodFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likelihoodFunc(W, x, y_train, likelihood_var):\n",
    "    '''\n",
    "    Implement likelihoodFunc. This function returns the \n",
    "    data likelihood\n",
    "    given f(y_train | x; W) ~ Normal(w^Tx, likelihood_var).\n",
    "\n",
    "    Args:\n",
    "        W: Weights\n",
    "        x: Training design matrix with first col all \n",
    "        ones (np.matrix)\n",
    "        y_train: Training response vector (np.matrix)\n",
    "        likelihood_var: likelihood variance\n",
    "\n",
    "    Returns:\n",
    "        likelihood: Data likelihood (float) - Gaussian pdf\n",
    "        Bagimsizlik assumptioni yaptik, carparak likelihood alacagiz\n",
    "    '''\n",
    "\n",
    "    mean = np.dot(np.transpose(W), x[i])\n",
    "    ## np.prod computes the gaussian pdf of the vector with independence assumption\n",
    "    likelihood = np.prod(np.array((np.exp(-((np.square(np.substract(x[i], mean))))/(2*(np.square(likelihood_var)))))/np.sqrt(2*((np.pi)*likelihood_var))))\n",
    "\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData(dataSize, noiseParams, actual_weights):\n",
    "    # x1: from [0,1) to [-1,1)\n",
    "    x1 = -1 + 2 * np.random.rand(1, dataSize)\n",
    "#     print ('x1 = ' + str(x1))\n",
    "    # appending the bias term\n",
    "    xtrain = np.matrix(np.c_[np.ones((dataSize, 1)), x1])\n",
    "#     print ('xtrain = ' + str(xtrain))\n",
    "    # random noise\n",
    "    noise = np.matrix(np.random.normal(\n",
    "                            noiseParams[\"mean\"],\n",
    "                            noiseParams[\"var\"],\n",
    "                            (dataSize, 1)))\n",
    "#     print ('noise = ' + str(noise))\n",
    "    ytrain = (xtrain * actual_weights) + noise\n",
    "\n",
    "    return xtrain, ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  22.],\n",
       "       [  1.,  33.],\n",
       "       [  1.,   4.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[np.ones((3 , 1)), [22, 33, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_weights = np.random.rand(50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noiseParams = {\"mean\": 10, \"var\":5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataSize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-6e442a8334b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerateData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoiseParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-dec5fb0b9220>\u001b[0m in \u001b[0;36mgenerateData\u001b[0;34m(dataSize, noiseParams, actual_weights)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print ('x1 = ' + str(x1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# appending the bias term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mxtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#     print ('xtrain = ' + str(xtrain))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# random noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "generateData(dataSize, noiseParams, actual_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 13.72438784,  13.38298747,  12.77021872, ...,  13.03335669,\n",
       "          13.70017636,  13.20091144],\n",
       "        [ 11.80569195,  11.48904093,  10.92426567, ...,  11.20942195,\n",
       "          11.83207583,  11.42179886],\n",
       "        [ 11.84791733,  11.57344121,  11.09045076, ...,  11.41312801,\n",
       "          11.9605198 ,  11.7018855 ],\n",
       "        ..., \n",
       "        [  7.84451   ,   7.48819133,   6.84649327, ...,   7.09635915,\n",
       "           7.78980087,   7.2368962 ],\n",
       "        [ 14.12000348,  13.77134243,  13.14449391, ...,  13.40117241,\n",
       "          14.08094892,  13.55557776],\n",
       "        [ 10.98552349,  10.65979415,  10.07741438, ...,  10.35449412,\n",
       "          10.99334846,  10.55042979]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateData(dataSize, noiseParams, actual_weights)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
