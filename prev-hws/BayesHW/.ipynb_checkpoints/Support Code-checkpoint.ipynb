{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.matlib as matlib\n",
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Notes for ML1003:\n",
    "\n",
    "This is support code provided for the Bayesian Regression Problems.\n",
    "The goal of this problem is to have you explore Bayesian Regression,\n",
    "as described in Lectur 11.b slides 13-25.\n",
    "\n",
    "A few things to note about this code:\n",
    "    - We strongly encourage you to review this support code prior to\n",
    "      completing \"problem.py\"\n",
    "    - For Problem (b), you are asked to generate plots for three\n",
    "      values of sigma_squared. We suggest you savid the plot generated\n",
    "      by make_plots (instead of simply calling plt.show)\n",
    "'''\n",
    "\n",
    "# Notes from intial author (prior to some)\n",
    "# translating the implementation at\n",
    "# https://github.com/probml/pmtk3/blob/master/demos/bayesLinRegDemo2d.m\n",
    "# into python\n",
    "#\n",
    "# Bayesian inference for simple linear regression with known noise variance\n",
    "# The goal is to reproduce fig 3.7 from Bishop's book\n",
    "# We fit the linear model f(x,w) = w0 + w1 x and plot the posterior over w.\n",
    "# This file is from pmtk3.googlecode.com\n",
    "# Given the mean = priorMu and covarianceMatrix = priorSigma of a prior\n",
    "# Gaussian distribution over regression parameters; observed data, xtrain\n",
    "# and ytrain; and the likelihood precision, generate the posterior\n",
    "# distribution, postW via Bayesian updating and return the updated values\n",
    "# for mu and sigma. xtrain is a design matrix whose first column is the all\n",
    "# ones vector.\n",
    "\n",
    "def generateData(dataSize, noiseParams, actual_weights):\n",
    "    # x1: from [0,1) to [-1,1)\n",
    "    x1 = -1 + 2 * np.random.rand(dataSize, 1)\n",
    "    # appending the bias term\n",
    "    xtrain = np.matrix(np.c_[np.ones((dataSize, 1)), x1])\n",
    "    # random noise\n",
    "    noise = np.matrix(np.random.normal(\n",
    "                            noiseParams[\"mean\"],\n",
    "                            noiseParams[\"var\"],\n",
    "                            (dataSize, 1)))\n",
    "\n",
    "    ytrain = (xtrain * actual_weights) + noise\n",
    "\n",
    "    return xtrain, ytrain\n",
    "\n",
    "def make_plots(actual_weights, xtrain, ytrain, likelihood_var, prior, likelihoodFunc, getPosteriorParams, getPredictiveParams):\n",
    "\n",
    "    # #setup for plotting\n",
    "    #\n",
    "    showProgressTillDataRows = [1, 2, 10, -1]\n",
    "    numRows = 1 + len(showProgressTillDataRows)\n",
    "    numCols = 4\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplots_adjust(hspace=.8, wspace=.8)\n",
    "\n",
    "    plotWithoutSeeingData(prior, numRows, numCols)\n",
    "\n",
    "    # see data for as many rounds as specified and plot\n",
    "    for roundNum, rowNum in enumerate(showProgressTillDataRows):\n",
    "        current_row = roundNum + 1\n",
    "        first_column_pos = (current_row * numCols) + 1\n",
    "\n",
    "        # #plot likelihood on latest point\n",
    "        plt.subplot(numRows, numCols, first_column_pos)\n",
    "\n",
    "\n",
    "        likelihoodFunc_with_data = lambda W: likelihoodFunc(W,\n",
    "                                                      xtrain[:rowNum,],\n",
    "                                                      ytrain[:rowNum],\n",
    "                                                      likelihood_var)\n",
    "        contourPlot(likelihoodFunc_with_data, actual_weights)\n",
    "\n",
    "        # plot updated posterior on points seen till now\n",
    "        x_seen = xtrain[:rowNum]\n",
    "        y_seen = ytrain[:rowNum]\n",
    "        mu, cov = getPosteriorParams(x_seen, y_seen,\n",
    "                                      prior, likelihood_var)\n",
    "        posteriorDistr = multivariate_normal(mu.T.tolist()[0], cov)\n",
    "        posteriorFunc = lambda x: posteriorDistr.pdf(x)\n",
    "        plt.subplot(numRows, numCols, first_column_pos + 1)\n",
    "        contourPlot(posteriorFunc, actual_weights)\n",
    "\n",
    "        # plot lines\n",
    "        dataSeen = np.c_[x_seen[:, 1], y_seen]\n",
    "        plt.subplot(numRows, numCols, first_column_pos + 2)\n",
    "        plotSampleLines(mu, cov, dataPoints=dataSeen)\n",
    "\n",
    "        # plot predictive\n",
    "        plt.subplot(numRows, numCols, first_column_pos + 3)\n",
    "        postMean, postVar = getPosteriorParams(x_seen, y_seen, prior)\n",
    "        plotPredictiveDistribution(getPredictiveParams, postMean, postVar)\n",
    "\n",
    "    # #show the final plot\n",
    "    plt.show()\n",
    "\n",
    "def plotWithoutSeeingData(prior, numRows, numCols):\n",
    "\n",
    "    #Blank likelihood\n",
    "    plt.subplot(numRows, numCols, 1, axisbg='grey')\n",
    "    plt.title(\"Likelihood\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlim([-0.9, 0.9])\n",
    "    plt.ylim([-0.9, 0.9])\n",
    "\n",
    "    #Prior\n",
    "    priorDistribution = multivariate_normal(mean=prior[\"mean\"].T.tolist()[0],\n",
    "        cov=prior[\"var\"])\n",
    "    priorFunc = lambda x:priorDistribution.pdf(x)\n",
    "    plt.subplot(numRows, numCols, 2)\n",
    "    plt.title(\"Prior/Posterior\")\n",
    "    contourPlot(priorFunc)\n",
    "\n",
    "    # Plot initially valid lines (no data seen)\n",
    "    plt.subplot(numRows, numCols, 3)\n",
    "    plt.title(\"Data Space\")\n",
    "    plotSampleLines(prior[\"mean\"], prior[\"var\"])\n",
    "\n",
    "    # Blank predictive\n",
    "    plt.subplot(numRows, numCols, 4, axisbg='grey')\n",
    "    plt.title('Predictive Distribution')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.ylim([-1, 1])\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "\n",
    "def contourPlot(distributionFunc, actualWeights=[]):\n",
    "\n",
    "    stepSize = 0.05\n",
    "    array = np.arange(-1, 1, stepSize)\n",
    "    x, y_train = np.meshgrid(array, array)\n",
    "\n",
    "    length = x.shape[0] * x.shape[1]\n",
    "    x_flat = x.reshape((length, 1))\n",
    "    y_flat = y_train.reshape((length, 1))\n",
    "    contourPoints = np.c_[x_flat, y_flat]\n",
    "\n",
    "    values = map(distributionFunc, contourPoints)\n",
    "    values = np.array(values).reshape(x.shape)\n",
    "\n",
    "    plt.contourf(x, y_train, values)\n",
    "    plt.xlabel(\"w1\")\n",
    "    plt.ylabel(\"w2\")\n",
    "    plt.xticks([-0.5, 0, 0.5])\n",
    "    plt.yticks([-0.5, 0, 0.5])\n",
    "    plt.xlim([-0.9, 0.9])\n",
    "    plt.ylim([-0.9, 0.9])\n",
    "\n",
    "    if(len(actualWeights) == 2):\n",
    "        plt.plot(float(actualWeights[0]), float(actualWeights[1]),\n",
    "                 \"*k\", ms=5)\n",
    "\n",
    "# Plot the specified number of lines of the form y_train = w0 + w1*x in [-1,1]x[-1,1] by\n",
    "# drawing w0, w1 from a bivariate normal distribution with specified values\n",
    "# for mu = mean and sigma = covariance Matrix. Also plot the data points as\n",
    "# circles.\n",
    "def plotSampleLines(mean, variance,\n",
    "                    numberOfLines=6,\n",
    "                    dataPoints=np.empty((0, 0))):\n",
    "    stepSize = 0.05\n",
    "    # generate and plot lines\n",
    "    for round in range(1, numberOfLines):\n",
    "        weights = np.matrix(np.random.multivariate_normal(mean.T.tolist()[0], variance)).T\n",
    "        x1 = np.arange(-1, 1, stepSize)\n",
    "        x = np.matrix(np.c_[np.ones((len(x1), 1)), x1])\n",
    "        y_train = x * weights\n",
    "\n",
    "        plt.plot(x1, y_train)\n",
    "\n",
    "    # markings\n",
    "    plt.xticks([-1, 0, 1])\n",
    "    plt.yticks([-1, 0, 1])\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.ylim([-1, 1])\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    # plot data points if given\n",
    "    if(dataPoints.size):\n",
    "        plt.plot(dataPoints[:, 0], dataPoints[:, 1],\n",
    "                 \"co\")\n",
    "\n",
    "def plotPredictiveDistribution(getPredictiveParams,postMean, postVar):\n",
    "    stepSize = 0.05\n",
    "    x = np.arange(-1, 1, stepSize)\n",
    "    x = np.matrix(np.c_[np.ones((len(x), 1)), x])\n",
    "    predMeans = np.zeros(x.shape[0])\n",
    "    predStds = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        predMeans[i], predStds[i] = getPredictiveParams(x[i,].T,\n",
    "                                                        postMean,\n",
    "                                                        postVar)\n",
    "    predStds = np.sqrt(predStds)\n",
    "    plt.plot(x[:,1], predMeans, 'b')\n",
    "    plt.plot(x[:,1], predMeans + predStds, 'b--')\n",
    "    plt.plot(x[:,1], predMeans - predStds, 'b--')\n",
    "    plt.xticks([-1, 0, 1])\n",
    "    plt.yticks([-0.5, 0, 0.5])\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.ylim([-1, 1])\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
